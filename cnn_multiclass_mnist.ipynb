{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T20:04:09.215482Z",
     "start_time": "2025-05-18T20:04:07.373842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import idx2numpy\n",
    "\n",
    "seed = 42\n",
    "images = idx2numpy.convert_from_file('./mnist_dataset/train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
    "labels = idx2numpy.convert_from_file('./mnist_dataset/train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "\n",
    "# test-limit dataset to single sample\n",
    "images = images[:200]\n",
    "labels = labels[:200]\n",
    "\n",
    "len(images), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T20:04:11.584701Z",
     "start_time": "2025-05-18T20:04:10.644312Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(img, fsize=2):\n",
    "    plt.figure(figsize=(fsize, fsize))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T20:04:11.680444Z",
     "start_time": "2025-05-18T20:04:11.608335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T20:04:13.374007Z",
     "start_time": "2025-05-18T20:04:12.155978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 74)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\"\"\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(images, labels, test_size=0.37, random_state=seed)\n",
    "len(X_train), len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T20:04:23.223120Z",
     "start_time": "2025-05-18T20:04:17.568869Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "\n",
    "class MNIST(Dataset):\n",
    "    def __init__(self, n_images, n_labels):\n",
    "        self.n_images = n_images\n",
    "        self.n_labels = n_labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.n_images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img = self.n_images[idx]\n",
    "        label = self.n_labels[idx]\n",
    "        img = torch.from_numpy(img).float().unsqueeze(0) / 255.0\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T20:04:23.234596Z",
     "start_time": "2025-05-18T20:04:23.230235Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = MNIST(X_train, Y_train)\n",
    "val_set = MNIST(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T20:04:28.241818Z",
     "start_time": "2025-05-18T20:04:28.237470Z"
    }
   },
   "outputs": [],
   "source": [
    "_batch_size = 8\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=_batch_size)\n",
    "val_dataloader = DataLoader(val_set, batch_size=_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1, 28, 28]), torch.Size([8]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleX, sampleY = next(iter(train_dataloader))\n",
    "sampleX.shape, sampleY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T20:04:35.481006Z",
     "start_time": "2025-05-18T20:04:35.470082Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_kernel(img, kernel):\n",
    "    # np-version\n",
    "    #return np.sum(np.multiply(img, kernel))\n",
    "    return torch.sum(img * kernel)\n",
    "\n",
    "def custom_conv(batch, kernel, bias):\n",
    "    bs, img_ch, img_w, img_h = batch.shape\n",
    "    k_count, k_ch, k_w, k_h = kernel.shape\n",
    "    \n",
    "    if img_ch != k_ch:\n",
    "        print('Different channels input')\n",
    "        return\n",
    "    \n",
    "    w, h = img_w - k_w + 1, img_h - k_h + 1    \n",
    "    \n",
    "    # np-version\n",
    "    #out = np.zeros((bs, k_count, w, h))\n",
    "    out = torch.zeros((bs, k_count, w, h))\n",
    "    \n",
    "    for b_id in range(bs):\n",
    "        current_sample = batch[b_id]\n",
    "\n",
    "        for ch in range(k_count):\n",
    "            current_kernel = kernel[ch]\n",
    "\n",
    "            for row in range(h):\n",
    "                for col in range(w):\n",
    "                    window = current_sample[:, row : row + k_h, col : col + k_w]\n",
    "                    out[b_id][ch][row][col] = apply_kernel(window, current_kernel)\n",
    "\n",
    "    if bias is not None:\n",
    "        out = out + bias.reshape(1, k_count, 1, 1)\n",
    "                    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T20:04:37.041577Z",
     "start_time": "2025-05-18T20:04:37.031832Z"
    }
   },
   "outputs": [],
   "source": [
    "def max_pool(sample, k_size=2):\n",
    "    \n",
    "    batch_d, sample_d, sample_w, sample_h = sample.shape\n",
    "    #out = np.zeros((batch_d, sample_d, sample_w // 2, sample_h // 2))\n",
    "    out = torch.zeros((batch_d, sample_d, sample_w // 2, sample_h // 2))\n",
    "    max_indices = torch.zeros_like(out, dtype=torch.long) # indexes where max val was, need for backprop\n",
    "    \n",
    "    for b in range(batch_d):\n",
    "        for d in range(sample_d):\n",
    "            for i in range(out.shape[-2]):\n",
    "                for j in range(out.shape[-1]):\n",
    "\n",
    "                    window = sample[b, d, i * 2 : i * 2 + 2, j * 2 : j * 2 + 2]\n",
    "                    #out[b, d, i, j] = torch.amax(window)\n",
    "                    \n",
    "                    flat_idx = torch.argmax(window)  # flat индекс в окне\n",
    "                    out[b, d, i, j] = window.reshape(-1)[flat_idx]\n",
    "                    \n",
    "                    max_indices[b, d, i, j] = flat_idx\n",
    "\n",
    "    return out, max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T20:04:36.591044Z",
     "start_time": "2025-05-18T20:04:36.580734Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_conv_backward(batch, kernel, dL_dout, bias=None):\n",
    "    # batch: [B, C_in, H_in, W_in]\n",
    "    # kernel: [C_out, C_in, K_h, K_w]\n",
    "    # dL_dout: [B, C_out, H_out, W_out]\n",
    "\n",
    "    B, C_in, H_in, W_in = batch.shape\n",
    "    C_out, _, K_h, K_w = kernel.shape\n",
    "    _, _, H_out, W_out = dL_dout.shape\n",
    "\n",
    "    # ---- Градиент по bias ----\n",
    "    dL_dbias = dL_dout.sum(dim=(0, 2, 3))  # [C_out]\n",
    "\n",
    "    # ---- kernel grad (им2кол) ----\n",
    "    # (B, C_in, H_in, W_in) -> (B, C_in*K_h*K_w, H_out*W_out)\n",
    "    patches = batch.unfold(2, K_h, 1).unfold(3, K_w, 1)  # (B, C_in, H_out, W_out, K_h, K_w)\n",
    "    patches = patches.permute(0,2,3,1,4,5).reshape(B, H_out*W_out, -1)  # (B, H_out*W_out, C_in*K_h*K_w)\n",
    "    patches = patches.permute(0,2,1)  # (B, C_in*K_h*K_w, H_out*W_out)\n",
    "\n",
    "    dL_dout_flat = dL_dout.reshape(B, C_out, -1)  # (B, C_out, H_out*W_out)\n",
    "\n",
    "    # (C_out, C_in*K_h*K_w)\n",
    "    grad_w = torch.einsum('bik,bjk->ij', dL_dout_flat, patches)  # sum по batch and spatial\n",
    "    dL_dkernel = grad_w.reshape(C_out, C_in, K_h, K_w)\n",
    "\n",
    "    # ---- batch grad (output grad -> input space свёртка \"полная\") ---\n",
    "    # Используем готовую PyTorch функцию:\n",
    "    dL_dbatch = torch.nn.grad.conv2d_input(\n",
    "        (B, C_in, H_in, W_in), kernel, dL_dout\n",
    "    )\n",
    "\n",
    "    return dL_dbias, dL_dkernel, dL_dbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T20:04:37.605937Z",
     "start_time": "2025-05-18T20:04:37.595586Z"
    }
   },
   "outputs": [],
   "source": [
    "def max_pool_backward(dout, max_indices, input_shape, k_size=2):\n",
    "    '''\n",
    "    dout        : [B, D, H_out, W_out] — градиент по выходу maxpool\n",
    "    max_indices : [B, D, H_out, W_out] — flat индексы максимумов (из форварда)\n",
    "    input_shape : (B, D, H_in, W_in)   — shape входа до maxpool\n",
    "    '''\n",
    "    B, D, H_out, W_out = dout.shape\n",
    "    H_in, W_in = input_shape[-2], input_shape[-1]\n",
    "    din = torch.zeros((B, D, H_in, W_in), dtype=dout.dtype, device=dout.device)\n",
    "\n",
    "    for b in range(B):\n",
    "        for d in range(D):\n",
    "            for i in range(H_out):\n",
    "                for j in range(W_out):\n",
    "                    idx = max_indices[b, d, i, j].item()\n",
    "                    di = idx // k_size  # индекс внутри окна по высоте\n",
    "                    dj = idx % k_size   # индекс внутри окна по ширине\n",
    "                    in_i = i * k_size + di\n",
    "                    in_j = j * k_size + dj\n",
    "                    din[b, d, in_i, in_j] += dout[b, d, i, j]\n",
    "    return din"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T20:04:38.103159Z",
     "start_time": "2025-05-18T20:04:38.098876Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_acc(logits, gt):\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    pred_classes = torch.argmax(probs, dim=1)\n",
    "    \n",
    "    acc = (pred_classes == gt).sum().item() / len(gt)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T20:04:38.384958Z",
     "start_time": "2025-05-18T20:04:38.380328Z"
    }
   },
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T20:04:39.414818Z",
     "start_time": "2025-05-18T20:04:39.400738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=400, out_features=32, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 8, 3), # (8, 26, 26)\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(8, 16, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 10)\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "_lr = 1e-1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----- Epoch: 0 -----\n",
      "Train loss: 2.3070 acc: 0.1042\n",
      "Val loss: 2.2951 acc: 0.1000\n",
      " ----- Epoch: 1 -----\n",
      "Train loss: 2.2637 acc: 0.1849\n",
      "Val loss: 2.2569 acc: 0.1625\n",
      " ----- Epoch: 2 -----\n",
      "Train loss: 2.1664 acc: 0.2734\n",
      "Val loss: 2.0907 acc: 0.2875\n",
      " ----- Epoch: 3 -----\n",
      "Train loss: 1.9029 acc: 0.3411\n",
      "Val loss: 1.6123 acc: 0.5375\n",
      " ----- Epoch: 4 -----\n",
      "Train loss: 1.4591 acc: 0.5286\n",
      "Val loss: 1.3118 acc: 0.6000\n",
      " ----- Epoch: 5 -----\n",
      "Train loss: 0.9666 acc: 0.6693\n",
      "Val loss: 0.9394 acc: 0.7000\n",
      " ----- Epoch: 6 -----\n",
      "Train loss: 0.7033 acc: 0.7578\n",
      "Val loss: 0.7151 acc: 0.8000\n",
      " ----- Epoch: 7 -----\n",
      "Train loss: 0.4964 acc: 0.8359\n",
      "Val loss: 0.6029 acc: 0.8500\n",
      " ----- Epoch: 8 -----\n",
      "Train loss: 0.3947 acc: 0.8828\n",
      "Val loss: 0.5509 acc: 0.8875\n",
      " ----- Epoch: 9 -----\n",
      "Train loss: 0.2670 acc: 0.9062\n",
      "Val loss: 0.5114 acc: 0.8875\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "current_eph = 0\n",
    "\n",
    "for eph in range(current_eph, current_eph + 10):\n",
    "    print(f\" {'-' * 5} Epoch: {eph} {'-' * 5}\")\n",
    "    current_eph += 1\n",
    "    t_losses = []\n",
    "    t_acc = []\n",
    "    \n",
    "    for X, Y in train_dataloader:\n",
    "        out = model(X)\n",
    "        \n",
    "        acc = get_acc(out, Y)\n",
    "        t_acc.append(acc)\n",
    "        \n",
    "        loss = criterion(out, Y)\n",
    "        t_losses.append(loss.item())\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        for param in model.parameters():\n",
    "            if param.grad is not None:\n",
    "                param.data += -_lr * param.grad\n",
    "\n",
    "    loss_eph = sum(t_losses) / len(t_losses)    \n",
    "    avg_acc = sum(t_acc) / len(t_acc)\n",
    "    print(f'Train loss: {loss_eph:.4f} acc: {avg_acc:.4f}')\n",
    "    \n",
    "    v_losses = []\n",
    "    v_acc = []\n",
    "\n",
    "    for X, Y in val_dataloader:\n",
    "        out = model(X)\n",
    "        \n",
    "        acc = get_acc(out, Y)\n",
    "        v_acc.append(acc)\n",
    "        \n",
    "        loss = criterion(out, Y)\n",
    "        v_losses.append(loss.item())\n",
    "\n",
    "    loss_eph = sum(v_losses) / len(v_losses)    \n",
    "    avg_acc = sum(v_acc) / len(v_acc)\n",
    "    print(f'Val loss: {loss_eph:.4f} acc: {avg_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def get_init_bounds(fan_in):\n",
    "#     a = np.sqrt(5)\n",
    "#     gain = np.sqrt(2.0 / (1 + a**2))\n",
    "\n",
    "#     bound = gain * np.sqrt(3 / fan_in)\n",
    "#     return bound\n",
    "\n",
    "# conv1_bound = get_init_bounds(1 * 3 * 3)\n",
    "# conv1W = np.random.uniform(-conv1_bound, conv1_bound, (8, 1, 3, 3))\n",
    "# conv1b = np.random.uniform(-conv1_bound, conv1_bound, (8))\n",
    "\n",
    "# conv2_bound = get_init_bounds(8 * 3 * 3)\n",
    "# conv2W = np.random.uniform(-conv2_bound, conv2_bound, (16, 8, 3, 3))\n",
    "# conv2b = np.random.uniform(-conv2_bound, conv2_bound, (16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model from scratch with tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1W = model[0].weight.clone().detach() # (8, 1, 3, 3) out_ch / in_ch / k_w / k_h\n",
    "conv1b = model[0].bias.clone().detach() # (8)\n",
    "\n",
    "conv2W = model[3].weight.clone().detach() # (16, 8, 3, 3)\n",
    "conv2b = model[3].bias.clone().detach() # (16)\n",
    "\n",
    "W1 = model[7].weight.clone().detach().T # (16 * 5 * 5, 32)\n",
    "b1 = model[7].bias.clone().detach().T # (32)\n",
    "\n",
    "W2 = model[9].weight.clone().detach().T # (32, 10)\n",
    "b2 = model[9].bias.clone().detach().T # (10)\n",
    "\n",
    "parameters = [conv1W, conv1b, conv2W, conv2b, W1, b1, W2, b2]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "sum([p.nelement() for p in parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1, 3, 3]),\n",
       " torch.Size([8]),\n",
       " torch.Size([16, 8, 3, 3]),\n",
       " torch.Size([16]),\n",
       " torch.Size([400, 32]),\n",
       " torch.Size([32]),\n",
       " torch.Size([32, 10]),\n",
       " torch.Size([10]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1W.shape, conv1b.shape, conv2W.shape, conv2b.shape, W1.shape, b1.shape, W2.shape, b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T19:57:54.965109Z",
     "start_time": "2025-05-18T19:57:54.961855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.248547077178955"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out = model(sampleX)\n",
    "torch_loss = criterion(torch_out, sampleY)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "torch_loss.backward()\n",
    "\n",
    "torch_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T19:58:07.219871Z",
     "start_time": "2025-05-18T19:57:55.566147Z"
    }
   },
   "outputs": [],
   "source": [
    "c1 = custom_conv(sampleX, conv1W, conv1b)\n",
    "r1 = torch.clamp(c1, min=0)\n",
    "p1, p1_max_idx = max_pool(r1)\n",
    "\n",
    "c2 = custom_conv(p1, conv2W, conv2b)\n",
    "r2 = torch.clamp(c2, min=0)\n",
    "p2, p2_max_idx = max_pool(r2)\n",
    "flatten = p2.view((_batch_size, -1))\n",
    "\n",
    "Z1 = flatten @ W1 + b1\n",
    "A1 = torch.clamp(Z1, min=0)\n",
    "logits = A1 @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(torch_out, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T19:58:15.216099Z",
     "start_time": "2025-05-18T19:58:15.082742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2485, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = logits.exp()\n",
    "counts_sum = counts.sum(axis=1, keepdims=True)\n",
    "probs = counts / counts_sum\n",
    "\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(_batch_size), sampleY].mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T19:58:23.244943Z",
     "start_time": "2025-05-18T19:58:23.236638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2              | exact: False | approximate: True  | maxdiff: 8.381903171539307e-09\n",
      "b2              | exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n",
      "w2              | exact: False | approximate: True  | maxdiff: 1.1175870895385742e-08\n",
      "b2              | exact: False | approximate: True  | maxdiff: 1.1175870895385742e-08\n",
      "conv2W          | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "conv2b          | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "conv1W          | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "conv1b          | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n"
     ]
    }
   ],
   "source": [
    "batch = logits.shape[0]\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "\n",
    "one_hot = torch.zeros_like(probs)\n",
    "one_hot[torch.arange(batch), sampleY] = 1\n",
    "\n",
    "dlogits = (probs - one_hot) / _batch_size\n",
    "\n",
    "dW2 = A1.T @ dlogits\n",
    "db2 = dlogits.sum(axis=0)\n",
    "\n",
    "cmp('w2', dW2.T, model[-1].weight)\n",
    "cmp('b2', db2.T, model[-1].bias)\n",
    "\n",
    "dA1 = dlogits @ W2.T\n",
    "dZ1 = dA1 * (Z1 > 0).float()\n",
    "\n",
    "dW1 = flatten.T @ dZ1\n",
    "db1 = dZ1.sum(axis=0)\n",
    "\n",
    "cmp('w2', dW1.T, model[-3].weight)\n",
    "cmp('b2', db1.T, model[-3].bias)\n",
    "\n",
    "dflatten = dZ1 @ W1.T\n",
    "\n",
    "dp2 = dflatten.view(p2.shape)\n",
    "dr2 = max_pool_backward(dp2, p2_max_idx, r2.shape)\n",
    "\n",
    "dc2 = (dr2 * (c2 > 0))\n",
    "\n",
    "dconv2b, dconv2W, dp1 = custom_conv_backward(p1, conv2W, dc2)\n",
    "cmp('conv2W', dconv2W, model[3].weight)\n",
    "cmp('conv2b', dconv2b, model[3].bias)\n",
    "\n",
    "dr1 = max_pool_backward(dp1, p1_max_idx, r1.shape)\n",
    "dc1 = (dr1 * (c1 > 0))\n",
    "\n",
    "dconv1b, dconv1W, dp1 = custom_conv_backward(sampleX, conv1W, dc1)\n",
    "\n",
    "cmp('conv1W', dconv1W, model[0].weight)\n",
    "cmp('conv1b', dconv1b, model[0].bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-18T20:05:00.090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----- Epoch: 0 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [01:40<00:00,  6.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.3070 acc: 0.1042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:49<00:00,  4.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 2.2951 acc: 0.1000\n",
      " ----- Epoch: 1 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [01:45<00:00,  6.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.2637 acc: 0.1849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:02<00:00,  6.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 2.2569 acc: 0.1625\n",
      " ----- Epoch: 2 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [02:00<00:00,  7.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1664 acc: 0.2734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:57<00:00,  5.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 2.0907 acc: 0.2875\n",
      " ----- Epoch: 3 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [02:06<00:00,  7.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9029 acc: 0.3411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:00<00:00,  6.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 1.6123 acc: 0.5375\n",
      " ----- Epoch: 4 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [02:02<00:00,  7.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.4591 acc: 0.5286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:02<00:00,  6.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 1.3118 acc: 0.6000\n",
      " ----- Epoch: 5 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [02:06<00:00,  7.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.9666 acc: 0.6693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:05<00:00,  6.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.9394 acc: 0.7000\n",
      " ----- Epoch: 6 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [02:04<00:00,  7.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7033 acc: 0.7578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:01<00:00,  6.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.7151 acc: 0.8000\n",
      " ----- Epoch: 7 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [02:02<00:00,  7.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4964 acc: 0.8359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:01<00:00,  6.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6029 acc: 0.8500\n",
      " ----- Epoch: 8 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [02:08<00:00,  8.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3947 acc: 0.8828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:00<00:00,  6.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5509 acc: 0.8875\n",
      " ----- Epoch: 9 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [01:59<00:00,  7.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.2670 acc: 0.9062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:58<00:00,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5114 acc: 0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "current_eph = 0\n",
    "\n",
    "for eph in range(current_eph, current_eph + 10):\n",
    "    print(f\" {'-' * 5} Epoch: {eph} {'-' * 5}\")\n",
    "    current_eph += 1\n",
    "    t_losses = []\n",
    "    t_acc = []\n",
    "    \n",
    "    for X, Y in tqdm.tqdm(train_dataloader):\n",
    "        _batch_size = X.shape[0]\n",
    "                \n",
    "        # forward pass\n",
    "        c1 = custom_conv(X, conv1W, conv1b)\n",
    "        r1 = torch.clamp(c1, min=0)\n",
    "        p1, p1_max_idx = max_pool(r1)\n",
    "\n",
    "        c2 = custom_conv(p1, conv2W, conv2b)\n",
    "        r2 = torch.clamp(c2, min=0)\n",
    "        p2, p2_max_idx = max_pool(r2)\n",
    "        flatten = p2.view((_batch_size, -1))\n",
    "\n",
    "        Z1 = flatten @ W1 + b1\n",
    "        A1 = torch.clamp(Z1, min=0)\n",
    "        logits = A1 @ W2 + b2\n",
    "\n",
    "        acc = get_acc(logits, Y)\n",
    "        t_acc.append(acc)\n",
    "        \n",
    "        # loss\n",
    "        counts = logits.exp()\n",
    "        counts_sum = counts.sum(axis=1, keepdims=True)\n",
    "        probs = counts / counts_sum\n",
    "\n",
    "        logprobs = probs.log()\n",
    "        loss = -logprobs[range(_batch_size), Y].mean()\n",
    "        t_losses.append(loss)\n",
    "\n",
    "        # backprop\n",
    "        # backprop loss\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "\n",
    "        one_hot = torch.zeros_like(probs)\n",
    "        one_hot[torch.arange(_batch_size), Y] = 1\n",
    "\n",
    "        dlogits = (probs - one_hot) / _batch_size\n",
    "\n",
    "        # backprop fc2\n",
    "        dW2 = A1.T @ dlogits\n",
    "        db2 = dlogits.sum(axis=0)\n",
    "        \n",
    "        # backprop non-linearity\n",
    "        dA1 = dlogits @ W2.T\n",
    "        dZ1 = dA1 * (Z1 > 0).float()\n",
    "\n",
    "        # backprop fc1\n",
    "        dW1 = flatten.T @ dZ1\n",
    "        db1 = dZ1.sum(axis=0)\n",
    "        \n",
    "        # backprop flatten\n",
    "        dflatten = dZ1 @ W1.T\n",
    "        dp2 = dflatten.view(p2.shape)\n",
    "\n",
    "        # backprop max_pool\n",
    "        dr2 = max_pool_backward(dp2, p2_max_idx, r2.shape)\n",
    "\n",
    "        # backprop ReLU with conv2\n",
    "        dc2 = (dr2 * (c2 > 0))\n",
    "        dconv2b, dconv2W, dp1 = custom_conv_backward(p1, conv2W, dc2)\n",
    "        \n",
    "        # backprop max_pool\n",
    "        dr1 = max_pool_backward(dp1, p1_max_idx, r1.shape)\n",
    "\n",
    "        # backprop ReLU with conv1\n",
    "        dc1 = (dr1 * (c1 > 0))\n",
    "        dconv1b, dconv1W, dp1 = custom_conv_backward(X, conv1W, dc1)\n",
    "\n",
    "        # parameters = [conv1W, conv1b, conv2W, conv2b, W1, b1, W2, b2]\n",
    "        grads = [dconv1W, dconv1b, dconv2W, dconv2b, dW1, db1, dW2, db2]\n",
    "\n",
    "        for param, grad in zip(parameters, grads):\n",
    "            param.data += -_lr * grad\n",
    "          \n",
    "    loss_eph = sum(t_losses) / len(t_losses)    \n",
    "    avg_acc = sum(t_acc) / len(t_acc)\n",
    "    print(f'Train loss: {loss_eph:.4f} acc: {avg_acc:.4f}')\n",
    "    \n",
    "    v_losses = []\n",
    "    v_acc = []\n",
    "\n",
    "    for X, Y in tqdm.tqdm(val_dataloader):\n",
    "        _batch_size = X.shape[0]\n",
    "\n",
    "        # forward pass\n",
    "        c1 = custom_conv(X, conv1W, conv1b)\n",
    "        r1 = torch.clamp(c1, min=0)\n",
    "        p1, p1_max_idx = max_pool(r1)\n",
    "\n",
    "        c2 = custom_conv(p1, conv2W, conv2b)\n",
    "        r2 = torch.clamp(c2, min=0)\n",
    "        p2, p2_max_idx = max_pool(r2)\n",
    "        flatten = p2.view((_batch_size, -1))\n",
    "\n",
    "        Z1 = flatten @ W1 + b1\n",
    "        A1 = torch.clamp(Z1, min=0)\n",
    "        logits = A1 @ W2 + b2\n",
    "\n",
    "        acc = get_acc(logits, Y)\n",
    "        v_acc.append(acc)\n",
    "\n",
    "        # loss\n",
    "        counts = logits.exp()\n",
    "        counts_sum = counts.sum(axis=1, keepdims=True)\n",
    "        probs = counts / counts_sum\n",
    "\n",
    "        logprobs = probs.log()\n",
    "        loss = -logprobs[range(_batch_size), Y].mean()\n",
    "        v_losses.append(loss)\n",
    "\n",
    "    loss_eph = sum(v_losses) / len(v_losses)    \n",
    "    avg_acc = sum(v_acc) / len(v_acc)\n",
    "    print(f'Val loss: {loss_eph:.4f} acc: {avg_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:54:07.093067Z",
     "start_time": "2025-05-14T14:54:07.086028Z"
    }
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:14:16.549744Z",
     "start_time": "2025-05-16T10:14:16.287811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = idx2numpy.convert_from_file('./mnist_dataset/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n",
    "test_labels = idx2numpy.convert_from_file('./mnist_dataset/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n",
    "\n",
    "len(test_images), len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T19:32:51.044709Z",
     "start_time": "2025-05-14T19:32:50.998642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=9\n"
     ]
    }
   ],
   "source": [
    "idx = 7\n",
    "imshow(test_images[idx])\n",
    "print(f'label={test_labels[idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T19:48:31.977869Z",
     "start_time": "2025-05-14T19:48:31.970974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = torch.tensor(test_images[idx]) / 255.0\n",
    "sample = sample.unsqueeze(0).unsqueeze(0)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T19:48:32.855142Z",
     "start_time": "2025-05-14T19:48:32.848845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = torch.tensor(test_labels[idx]).unsqueeze(0)\n",
    "gt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "_batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass\n",
    "c1 = custom_conv(sample, conv1W, conv1b)\n",
    "r1 = torch.clamp(c1, min=0)\n",
    "p1, p1_max_idx = max_pool(r1)\n",
    "\n",
    "c2 = custom_conv(p1, conv2W, conv2b)\n",
    "r2 = torch.clamp(c2, min=0)\n",
    "p2, p2_max_idx = max_pool(r2)\n",
    "\n",
    "flatten = p2.view((_batch_size, -1))\n",
    "\n",
    "Z1 = flatten @ W1 + b1\n",
    "A1 = torch.clamp(Z1, min=0)\n",
    "logits = A1 @ W2 + b2\n",
    "\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.1558,  1.1184, -3.5678, -0.1521,  2.1424, -1.3913, -0.6258, -2.2217,\n",
       "          2.3161,  4.0951]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.3403e-06, 3.6629e-02, 3.3778e-04, 1.0281e-02, 1.0199e-01, 2.9776e-03,\n",
       "         6.4019e-03, 1.2978e-03, 1.2132e-01, 7.1876e-01]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.softmax(logits, dim=1)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class = torch.argmax(probs, dim=1)\n",
    "pred_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T19:48:33.934683Z",
     "start_time": "2025-05-14T19:48:33.923576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.1558,  1.1184, -3.5678, -0.1521,  2.1424, -1.3913, -0.6258, -2.2217,\n",
       "          2.3160,  4.0951]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out = model(sample)\n",
    "torch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.3404e-06, 3.6629e-02, 3.3778e-04, 1.0281e-02, 1.0199e-01, 2.9776e-03,\n",
       "         6.4020e-03, 1.2978e-03, 1.2132e-01, 7.1875e-01]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_probs = torch.softmax(torch_out, dim=1)\n",
    "torch_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_pred_class = torch_probs.argmax(dim=1)\n",
    "torch_pred_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outputs after 10 epochs are nearly equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.7684e-07, -5.1260e-06, -5.7220e-06,  2.1756e-06, -1.1921e-06,\n",
       "         -4.0531e-06, -6.9141e-06,  6.9141e-06,  3.0994e-06,  3.3379e-06]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits - torch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5466e-11, -2.6450e-07, -2.6776e-09, -2.7940e-09, -3.4273e-07,\n",
       "         -1.7928e-08, -5.6345e-08,  5.8208e-09,  1.1921e-07,  8.3447e-07]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs - torch_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T07:41:33.054807Z",
     "start_time": "2025-05-15T07:41:31.504472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc 0.7801\n"
     ]
    }
   ],
   "source": [
    "test_set = MNIST(test_images, test_labels)\n",
    "test_dataloader = DataLoader(test_set, batch_size=_batch_size)\n",
    "\n",
    "acc = []\n",
    "\n",
    "for X, Y in test_dataloader:\n",
    "    out = model(X)\n",
    "    acc.append(get_acc(out, Y))\n",
    "    \n",
    "print(f'Test acc {sum(acc) / len(acc):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
